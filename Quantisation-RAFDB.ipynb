{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "smooth-romance",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hollow-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "from fer_model import get_fer_model\n",
    "import tensorflow as tf\n",
    "import tempfile \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worst-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "TIMESTAMP = round(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bigger-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-regulation",
   "metadata": {},
   "source": [
    "# Loading the CK+ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hidden-privacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12271 images belonging to 7 classes.\n",
      "Found 3068 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from data import load_rafdb\n",
    "train_generator = load_rafdb(\"train\")\n",
    "test_generator = load_rafdb(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-institution",
   "metadata": {},
   "source": [
    "# Load Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wound-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_fer_model(input_size=100, input_channels=1, out_classes=7)\n",
    "model.load_weights(\"weights_rafdb/model_weights_1626211720.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-journalism",
   "metadata": {},
   "source": [
    "### Baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "discrete-courage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model performance:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'size': 29801682,\n",
       " 'acc': 0.8246414602346805,\n",
       " 'f_acc': 0.8333333333333334,\n",
       " 'm_acc': 0.8054443554843875,\n",
       " 'caucasian_acc': 0.8192258613356018,\n",
       " 'afamerican_acc': 0.8675213675213675,\n",
       " 'asian_acc': 0.8302277432712215,\n",
       " 'age0_acc': 0.8996960486322189,\n",
       " 'age1_acc': 0.8292181069958847,\n",
       " 'age2_acc': 0.8044524669073405,\n",
       " 'age3_acc': 0.8585657370517928,\n",
       " 'age4_acc': 0.7078651685393258}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluation import get_metrics_rafdb\n",
    "print(\"Baseline model performance:\")\n",
    "get_metrics_rafdb(model, test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-giving",
   "metadata": {},
   "source": [
    "# Apply Quantisation to the Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interim-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# This optimisation includes the quantisation \n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-scanning",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recreational-encounter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 100 results so far.\n",
      "Evaluated on 200 results so far.\n",
      "Evaluated on 300 results so far.\n",
      "Evaluated on 400 results so far.\n",
      "Evaluated on 500 results so far.\n",
      "Evaluated on 600 results so far.\n",
      "Evaluated on 700 results so far.\n",
      "Evaluated on 800 results so far.\n",
      "Evaluated on 900 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 1100 results so far.\n",
      "Evaluated on 1200 results so far.\n",
      "Evaluated on 1300 results so far.\n",
      "Evaluated on 1400 results so far.\n",
      "Evaluated on 1500 results so far.\n",
      "Evaluated on 1600 results so far.\n",
      "Evaluated on 1700 results so far.\n",
      "Evaluated on 1800 results so far.\n",
      "Evaluated on 1900 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 2100 results so far.\n",
      "Evaluated on 2200 results so far.\n",
      "Evaluated on 2300 results so far.\n",
      "Evaluated on 2400 results so far.\n",
      "Evaluated on 2500 results so far.\n",
      "Evaluated on 2600 results so far.\n",
      "Evaluated on 2700 results so far.\n",
      "Evaluated on 2800 results so far.\n",
      "Evaluated on 2900 results so far.\n",
      "Evaluated on 3000 results so far.\n"
     ]
    }
   ],
   "source": [
    "from evaluation import get_metrics_quantised\n",
    "metrics = get_metrics_quantised(quantized_tflite_model, test_generator, dataset=\"rafdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fourth-tackle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantised model performance:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'size': 6568174,\n",
       " 'acc': 0.8246414602346805,\n",
       " 'f_acc': 0.8320987654320988,\n",
       " 'm_acc': 0.8070456365092074,\n",
       " 'caucasian_acc': 0.8192258613356018,\n",
       " 'afamerican_acc': 0.8675213675213675,\n",
       " 'asian_acc': 0.8302277432712215,\n",
       " 'age0_acc': 0.8996960486322189,\n",
       " 'age1_acc': 0.8292181069958847,\n",
       " 'age2_acc': 0.8050541516245487,\n",
       " 'age3_acc': 0.8565737051792829,\n",
       " 'age4_acc': 0.7078651685393258}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Quantised model performance:\")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-default",
   "metadata": {},
   "source": [
    "### Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aerial-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"logs_rafdb/quantised_model_metrics_%s\" % TIMESTAMP, \n",
    "          'wb') as quantised_model_metrics_file:\n",
    "        pickle.dump(metrics, quantised_model_metrics_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
