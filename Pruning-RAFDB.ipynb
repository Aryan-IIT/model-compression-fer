{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sudden-renewal",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "from fer_model import get_fer_model\n",
    "import tensorflow as tf\n",
    "import tempfile \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import pickle\n",
    "\n",
    "from evaluation import get_metrics_rafdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-schema",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "TIMESTAMP = round(time.time())\n",
    "print(\"Timestamp is\", TIMESTAMP)\n",
    "if \"SPARSITY\" not in locals(): \n",
    "    SPARSITY = 0.6\n",
    "print(\"SPARSITY =\", SPARSITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-answer",
   "metadata": {},
   "source": [
    "# Loading the RAFDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_rafdb\n",
    "train_generator = load_rafdb(\"train\")\n",
    "test_generator = load_rafdb(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-token",
   "metadata": {},
   "source": [
    "# Load Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_fer_model(input_size=100, input_channels=1, out_classes=7)\n",
    "model.load_weights(\"weights_rafdb/model_weights_1626211720.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-receptor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Baseline model performance:\")\n",
    "file = open(\"logs_rafdb/model_metrics_1626211720\", \"rb\")\n",
    "baseline_metrics = pickle.load(file)\n",
    "for x, y in baseline_metrics.items(): \n",
    "    print(x, \"-->\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-margin",
   "metadata": {},
   "source": [
    "# Apply Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(model, sparsity=0.8):\n",
    "    \n",
    "    epochs = 2\n",
    "    \n",
    "    pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(\n",
    "            sparsity, 0, end_step=-1, frequency=32\n",
    "        )\n",
    "    }\n",
    "    model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "    opt = Adam(lr=0.0005)\n",
    "    model_for_pruning.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Fine-Tuning \n",
    "    logdir = tempfile.mkdtemp()\n",
    "    print(\"Saving logs to:\", logdir)\n",
    "\n",
    "    steps_per_epoch = train_generator.n//train_generator.batch_size\n",
    "    validation_steps = test_generator.n//test_generator.batch_size\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                                  patience=2, min_lr=0.00001, mode='auto')\n",
    "    checkpoint_name = \"weights_rafdb/pruned_model_weights_s%d_%s.h5\" % (sparsity*100, TIMESTAMP)\n",
    "    checkpoint = ModelCheckpoint(checkpoint_name, \n",
    "                                 monitor='val_accuracy', \n",
    "                                 save_weights_only=True,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='max', verbose=1)\n",
    "    callbacks = [PlotLossesKerasTF(), \n",
    "                 checkpoint, \n",
    "                 reduce_lr, \n",
    "                 tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "                 tfmot.sparsity.keras.PruningSummaries(log_dir=logdir)]\n",
    "\n",
    "    model_for_pruning.fit(\n",
    "        x=train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        validation_data = test_generator,\n",
    "        validation_steps = validation_steps,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    # Only use the best weights \n",
    "    model_for_pruning.load_weights(checkpoint_name)\n",
    "    model_for_pruning = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "    model_for_pruning.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model_for_pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-interval",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pruned_model = prune(model, sparsity=SPARSITY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-corpus",
   "metadata": {},
   "source": [
    "# Evaluate Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model performance after pruning:\")\n",
    "metrics = get_metrics_rafdb(pruned_model, test_generator)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-conversation",
   "metadata": {},
   "source": [
    "### Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"logs_rafdb/pruned_model_metrics_s%d_%s\" % (SPARSITY*100, TIMESTAMP), 'wb') as pruned_model_metrics_file:\n",
    "        pickle.dump(metrics, pruned_model_metrics_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-capacity",
   "metadata": {},
   "source": [
    "# Apply Quantisation to the Pruned Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
    "# This optimisation includes the quantisation \n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-natural",
   "metadata": {},
   "source": [
    "# Evaluate Pruned and Quantised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-paraguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import get_metrics_quantised\n",
    "metrics = get_metrics_quantised(quantized_and_pruned_tflite_model, test_generator, dataset=\"rafdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pruned and quantised model performance:\")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-execution",
   "metadata": {},
   "source": [
    "### Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"logs_rafdb/pruned_and_quantised_model_metrics_s%d_%s\" % (SPARSITY*100, TIMESTAMP), \n",
    "          'wb') as pruned_and_quantised_model_metrics_file:\n",
    "        pickle.dump(metrics, pruned_and_quantised_model_metrics_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
